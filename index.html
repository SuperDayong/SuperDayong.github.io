<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"/>




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  




<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.1" />






<meta name="description" content="这是一个数据疯子的空间">
<meta property="og:type" content="website">
<meta property="og:title" content="Super霸王肉条条">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Super霸王肉条条">
<meta property="og:description" content="这是一个数据疯子的空间">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Super霸王肉条条">
<meta name="twitter:description" content="这是一个数据疯子的空间">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: '博主'
    }
  };
</script>

  <title> Super霸王肉条条 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  



  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "//hm.baidu.com/hm.js?6f1197aaf232ff9d09307423909b9fa4";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>








  
  
    
  

  <div class="container one-collumn sidebar-position-left 
   page-home 
 ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Super霸王肉条条</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">欢迎来到我的博客</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-home fa-fw"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-th fa-fw"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-user fa-fw"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-archive fa-fw"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-tags fa-fw"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-heartbeat fa-fw"></i> <br />
            
            公益404
          </a>
        </li>
      

      
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/04/20/Hadoop集群下Hbase搭建/" itemprop="url">
                  Hadoop集群下Hbase搭建
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-04-20T18:33:45+08:00" content="2016-04-20">
              2016-04-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
                  ， 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/分布式Hadoop配置/" itemprop="url" rel="index">
                    <span itemprop="name">分布式Hadoop配置</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/04/20/Hadoop集群下Hbase搭建/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/04/20/Hadoop集群下Hbase搭建/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
		  
		  

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="安装Zookeeper"><a href="#安装Zookeeper" class="headerlink" title="安装Zookeeper"></a>安装Zookeeper</h1><h2 id="安装配置Zookeeper"><a href="#安装配置Zookeeper" class="headerlink" title="安装配置Zookeeper"></a>安装配置Zookeeper</h2><h3 id="安装Zookeeper-1"><a href="#安装Zookeeper-1" class="headerlink" title="安装Zookeeper"></a>安装Zookeeper</h3><p>使用root账户登录master.hadoop机器。打开终端窗口，执行以下命令： </p>
<pre><code>cd /usr/local //进入local目录 
tar xzf zookeeper-3.4.6.tar.gz //解压缩zookeeper安装程序 
mv zookeeper-3.4.6 zookeeper //修改zookeeper安装目录名称
</code></pre><h3 id="配置Zookeeper环境变量"><a href="#配置Zookeeper环境变量" class="headerlink" title="配置Zookeeper环境变量"></a>配置Zookeeper环境变量</h3><p>打开/etc/profile文件，添加修改zookeeper环境变量信息，信息如下： </p>
<pre><code>export ZOOKEEPER_HOME=/usr/local/zookeeper 
export PATH=$PATH:$ZOOKEEPER_HOME/bin 
</code></pre><p>保存后，执行source /etc/profile，刷新系统环境变量。</p>
<h3 id="配置zoo-cfg"><a href="#配置zoo-cfg" class="headerlink" title="配置zoo.cfg"></a>配置zoo.cfg</h3><p>进入zookeeper安装目录下的conf目录，复制zoo_sample.cfg文件，将其改名为zoo.cfg，打开此文件，添加修改如下信息。 </p>
<pre><code>tickTime=2000 
initLimit=5 
syncLimit=2 
dataDir=/usr/local/temp/zookeeper 
dataLogDir=/usr/local/zookeeper/logs
clientPort=2181 
server.1=master.hadoop:2888:3888 
server.2=slave1.hadoop:2888:3888
</code></pre><h2 id="启动关闭Zookeeper"><a href="#启动关闭Zookeeper" class="headerlink" title="启动关闭Zookeeper"></a>启动关闭Zookeeper</h2><h3 id="启动zookeeper"><a href="#启动zookeeper" class="headerlink" title="启动zookeeper"></a>启动zookeeper</h3><p>启动master节点上的zookeeper和slave节点的zookeeper的命令式一样的。命令如下。 </p>
<pre><code>[root@master bin]# zkServer.sh start 

[root@master bin]# jps
</code></pre><h3 id="关闭zookeeper"><a href="#关闭zookeeper" class="headerlink" title="关闭zookeeper"></a>关闭zookeeper</h3><p>关闭master节点上的zookeeper和slave节点的zookeeper的命令式一样的。</p>
<pre><code>[root@master bin]# zkServer.sh stop
</code></pre><h1 id="安装配置HBase"><a href="#安装配置HBase" class="headerlink" title="安装配置HBase"></a>安装配置HBase</h1><h2 id="安装HBase"><a href="#安装HBase" class="headerlink" title="安装HBase"></a>安装HBase</h2><p>打开终端窗口，执行以下命令： </p>
<pre><code>cd /usr/local //进入local目录 
tar xzf hbase-1.0.3-bin.tar.gz //解压缩hbase安装程序 
mv hbase-1.0.3 hbase //修改hbase安装目录名称
</code></pre><h2 id="配置HBase环境变量"><a href="#配置HBase环境变量" class="headerlink" title="配置HBase环境变量"></a>配置HBase环境变量</h2><p>打开/etc/profile文件，添加HBase环境变量信息，信息如下： </p>
<pre><code>export HBASE_HOME=/usr/local/hbase
export PATH=$PATH:$HBASE_HOME/bin 
</code></pre><p>保存后，执行# source /etc/profile，刷新系统环境变量。</p>
<p>重复上述操作，为其他几个slave机进行同样的配置；</p>
<p>或者使用scp命令将profile文件直接复制到slave1节点中进行覆盖操作，命令如下： </p>
<pre><code>scp -r /etc/profile root@slave1.hadoop:/etc
</code></pre><h2 id="配置hbase-env-sh"><a href="#配置hbase-env-sh" class="headerlink" title="配置hbase-env.sh"></a>配置hbase-env.sh</h2><p>打开文件/usr/local/hbase/conf/hbase-env.sh，添加修改如下信息。 </p>
<pre><code>#Java安装位置 
export JAVA_HOME=/usr/local/java/jdk1.7.0_79

#采用独立的ZooKeeper 
export HBASE_MANAGES_ZK=false 

#HBase类路径 
export HBASE_CLASSPATH=/usr/local/hadoop/etc/hadoop 
export HBASE_PID_DIR=/usr/local/temp/hbase/pids
</code></pre><h2 id="配置hbase-site-xml"><a href="#配置hbase-site-xml" class="headerlink" title="配置hbase-site.xml"></a>配置hbase-site.xml</h2><pre><code>&lt;property&gt; 
    &lt;name&gt;hbase.rootdir&lt;/name&gt; 
    &lt;value&gt;hdfs://master.hadoop:9000/hbase&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.master&lt;/name&gt; 
    &lt;value&gt;hdfs://master.hadoop:60000&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.master.port&lt;/name&gt; 
    &lt;value&gt;60000&lt;/value&gt; 
&lt;/property&gt;

&lt;property&gt; 
    &lt;name&gt;hbase.master.maxclockskew&lt;/name&gt; 
    &lt;value&gt;180000&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; 
    &lt;value&gt;true&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; 
    &lt;value&gt;slave1.hadoop&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.zookeeper.property.clientPort&lt;/name&gt; 
    &lt;value&gt;2181&lt;/value&gt;
    &lt;description&gt;Property from ZooKeeper&apos;s config zoo.cfg.The port at which the clients will connect. &lt;/description&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; 
    &lt;value&gt;/usr/local/temp/zookeeper&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.tmp.dir&lt;/name&gt; 
    &lt;value&gt;/usr/local/temp/hbase&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;zookeeper.znode.parent&lt;/name&gt; 
    &lt;value&gt;/hbase&lt;/value&gt; 
&lt;/property&gt;

&lt;property&gt; 
    &lt;name&gt;zookeeper.session.timeout&lt;/name&gt; 
    &lt;value&gt;90000&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.regionserver.restart.on.zk.expire&lt;/name&gt; 
    &lt;value&gt;true&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.master.info.port&lt;/name&gt; 
    &lt;value&gt;60010&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.regionserver.info.port&lt;/name&gt;
    &lt;value&gt;60030&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.client.scanner.caching&lt;/name&gt; 
    &lt;value&gt;200&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.balancer.period&lt;/name&gt; 
    &lt;value&gt;300000&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.client.write.buffer&lt;/name&gt; 
    &lt;value&gt;10485760&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.hregion.majorcompaction&lt;/name&gt; 
    &lt;value&gt;7200000&lt;/value&gt; 
&lt;/property&gt;

&lt;property&gt; 
    &lt;name&gt;hbase.hregion.max.filesize&lt;/name&gt; 
    &lt;value&gt;67108864&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.hregion.memstore.flush.size&lt;/name&gt; 
    &lt;value&gt;1048576&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hbase.server.thread.wakefrequency&lt;/name&gt; 
    &lt;value&gt;30000&lt;/value&gt;
&lt;/property&gt;
</code></pre><h2 id="配置regionservers"><a href="#配置regionservers" class="headerlink" title="配置regionservers"></a>配置regionservers</h2><p>打开文件/usr/local/hbase/conf/regionservers，将作为data节点的slave主机名称分行输入进去并保存。 </p>
<pre><code>slave1.hadoop
</code></pre><h2 id="部署其他Slave节点"><a href="#部署其他Slave节点" class="headerlink" title="部署其他Slave节点"></a>部署其他Slave节点</h2><pre><code>scp -r /usr/local/hbase root@slave1.hadoop:/usr/local
</code></pre><h1 id="启动关闭HBase"><a href="#启动关闭HBase" class="headerlink" title="启动关闭HBase"></a>启动关闭HBase</h1><h2 id="启动HBase"><a href="#启动HBase" class="headerlink" title="启动HBase"></a>启动HBase</h2><h3 id="启动master节点上的hbase"><a href="#启动master节点上的hbase" class="headerlink" title="启动master节点上的hbase"></a>启动master节点上的hbase</h3><pre><code>[root@master bin]# start-hbase.sh
</code></pre><p>主界面： <a href="http://master.hadoop:60010" target="_blank" rel="external">http://master.hadoop:60010</a></p>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/04/20/CentOS7下分布式Hadoop/" itemprop="url">
                  CentOS7下分布式Hadoop
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-04-20T10:40:06+08:00" content="2016-04-20">
              2016-04-20
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
                  ， 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/分布式Hadoop配置/" itemprop="url" rel="index">
                    <span itemprop="name">分布式Hadoop配置</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/04/20/CentOS7下分布式Hadoop/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/04/20/CentOS7下分布式Hadoop/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
		  
		  

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="声明"><a href="#声明" class="headerlink" title="声明"></a>声明</h1><hr>
<p><strong>环境：VMware12,2个CentOS7虚拟机，一台虚拟机名称为master.hadoop(NameNode),一台为slave1.hadoop(DataNode)</strong></p>
<hr>
<h1 id="IP配置"><a href="#IP配置" class="headerlink" title="IP配置"></a>IP配置</h1><p>192.168.123.10 master.hadoop</p>
<p>192.168.123.11 slave1.hadoop</p>
<hr>
<h1 id="VMware安装和CentOS安装"><a href="#VMware安装和CentOS安装" class="headerlink" title="VMware安装和CentOS安装"></a>VMware安装和CentOS安装</h1><hr>
<p>百度一大堆，这里不再介绍，接下来直奔主题。</p>
<hr>
<h1 id="静态IP配置"><a href="#静态IP配置" class="headerlink" title="静态IP配置"></a>静态IP配置</h1><hr>
<p>在每个虚拟机中都要配置静态IP地址，因为VMware中虚拟机的IP地址默认配置策略是DHCP，<br>每次重启虚拟机后，IP地址都会发生变化，对于Hadoop集群来说，这是绝对不允许的。</p>
<hr>
<h2 id="关闭VMware的DHCP（自行百度）"><a href="#关闭VMware的DHCP（自行百度）" class="headerlink" title="关闭VMware的DHCP（自行百度）"></a>关闭VMware的DHCP（自行百度）</h2><h2 id="设置CentOS静态IP"><a href="#设置CentOS静态IP" class="headerlink" title="设置CentOS静态IP"></a>设置CentOS静态IP</h2><h3 id="修改-etc-sysconfig-network"><a href="#修改-etc-sysconfig-network" class="headerlink" title="修改/etc/sysconfig/network"></a>修改/etc/sysconfig/network</h3><p>添加：</p>
<pre><code>NETWORKING=yes 
HOSTNAME=master.hadoop 
GATEWAY=192.168.123.2
</code></pre><h3 id="修改-etc-sysconfig-network-scripts-ifcfg-eth0"><a href="#修改-etc-sysconfig-network-scripts-ifcfg-eth0" class="headerlink" title="修改/etc/sysconfig/network-scripts/ifcfg-eth0"></a>修改/etc/sysconfig/network-scripts/ifcfg-eth0</h3><h4 id="在centOS7里面没有-ifcfg-eth0-文件，将-ifcfg-eno1677773-文件重命名为-ifcfg-eth0"><a href="#在centOS7里面没有-ifcfg-eth0-文件，将-ifcfg-eno1677773-文件重命名为-ifcfg-eth0" class="headerlink" title="在centOS7里面没有 ifcfg-eth0 文件，将 ifcfg-eno1677773 文件重命名为 ifcfg-eth0"></a>在centOS7里面没有 <strong>ifcfg-eth0</strong> 文件，将 <strong>ifcfg-eno1677773</strong> 文件重命名为 <strong>ifcfg-eth0</strong></h4><pre><code>cd /etc/sysconfig/network-scripts
mv ifcfg-eno1677773 ifcfg-eth0
</code></pre><h4 id="修改操作文件"><a href="#修改操作文件" class="headerlink" title="修改操作文件"></a>修改操作文件</h4><pre><code>gedit /etc/sysconfig/grub  打开grub文件 
</code></pre><p>在文件中添加： net.ifnames=0 biosdevname=0，下图所示：</p>
<p><img src="http://i.imgur.com/e8UaMKp.png" alt=""></p>
<h4 id="重新生成GRUB配置并更新内核"><a href="#重新生成GRUB配置并更新内核" class="headerlink" title="重新生成GRUB配置并更新内核"></a>重新生成GRUB配置并更新内核</h4><p>执行：</p>
<pre><code>grub2-mkconfig -o /boot/grub2/grub.cfg
</code></pre><h4 id="修改-etc-sysconfig-network-scripts-ifcfg-eth0-1"><a href="#修改-etc-sysconfig-network-scripts-ifcfg-eth0-1" class="headerlink" title="修改/etc/sysconfig/network-scripts/ifcfg-eth0"></a>修改/etc/sysconfig/network-scripts/ifcfg-eth0</h4><p><img src="http://i.imgur.com/uw4CRZI.png" alt=""></p>
<p>HWADDR：MAC设备号，无需更改</p>
<p>需要增加：IPADDR,NETMASK,DNS1</p>
<p>将 BOOTPROTO 设置成 static</p>
<h3 id="etc-resolv-conf"><a href="#etc-resolv-conf" class="headerlink" title="/etc/resolv.conf"></a>/etc/resolv.conf</h3><p>配置好DNS SERVER后该文件会自动配置，可打开查看，无需再配</p>
<p>到这一步，master.hadoop 的静态 IP地址为： 192.168.123.10</p>
<hr>
<p><strong>在slave1.hadoop中同样进行配置</strong></p>
<hr>
<h2 id="配置hosts文件"><a href="#配置hosts文件" class="headerlink" title="配置hosts文件"></a>配置hosts文件</h2><p>192.168.123.10 master.hadoop</p>
<p>192.168.123.11 slave1.hadoop</p>
<hr>
<p><strong>在slave1.hadoop中同样进行配置</strong></p>
<hr>
<h1 id="JDK安装"><a href="#JDK安装" class="headerlink" title="JDK安装"></a>JDK安装</h1><p>在文章《CentOS7 JDK 环境搭建》 里面已经详细介绍</p>
<h1 id="配置ssh"><a href="#配置ssh" class="headerlink" title="配置ssh"></a>配置ssh</h1><p>之前文章中已经介绍过</p>
<p>在终端依次执行：</p>
<pre><code>ssh-keygen -t rsa -P &quot;&quot;
cat /root/.ssh/id_rsa.pub &gt;&gt; /root/.ssh/authorized_keys
ssh-copy-id -i /root/.ssh/id_rsa.pub root@slave1.hadoop
</code></pre><p>提示输入slave1.hadoop上的root用户密码，然后完成。</p>
<pre><code>ssh slave1.hadoop 无密码登陆
</code></pre><h1 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h1><p>安装的话之前在单机版中已经详细介绍，不过这里的核心文件配置需要进行改动</p>
<h2 id="环境变量设置"><a href="#环境变量设置" class="headerlink" title="环境变量设置"></a>环境变量设置</h2><pre><code>gedit /etc/profile
</code></pre><p>添加：</p>
<p>export HADOOP_HOME=/usr/local/hadoop</p>
<p>export HADOOP_COMMON_HOME=$HADOOP_HOME </p>
<p>export HADOOP_HDFS_HOME=$HADOOP_HOME</p>
<p>export HADOOP_MAPRED_HOME=$HADOOP_HOME</p>
<p>export HADOOP_YARN_HOME=$HADOOP_HOME </p>
<p>export HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop </p>
<p>export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$HADOOP_HOME/lib</p>
<p>export YARN_HOME=${HADOOP_HOME}</p>
<h2 id="配置核心文件"><a href="#配置核心文件" class="headerlink" title="配置核心文件"></a>配置核心文件</h2><h3 id="core-site-xml配置"><a href="#core-site-xml配置" class="headerlink" title="core-site.xml配置"></a>core-site.xml配置</h3><pre><code>&lt;property&gt; 
    &lt;name&gt;fs.defaultFS&lt;/name&gt; 
    &lt;value&gt;hdfs://master.hadoop:9000&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;io.file.buffer.size&lt;/name&gt; 
    &lt;value&gt;131072&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; 
    &lt;value&gt;/usr/local/temp&lt;/value&gt; 
    &lt;description&gt; Abase for other temporary directories.&lt;/description&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt; 
    &lt;value&gt;master.hadoop&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt; 
    &lt;value&gt;*&lt;/value&gt; 
&lt;/property&gt;
</code></pre><h3 id="hadoop-env-sh配置"><a href="#hadoop-env-sh配置" class="headerlink" title="hadoop-env.sh配置"></a>hadoop-env.sh配置</h3><pre><code>export HADOOP_PID_DIR=/usr/local/temp/hadoop/pids
export JAVA_HOME=/usr/local/java/jdk1.7.0_79
</code></pre><h3 id="hdfs-site-xml配置"><a href="#hdfs-site-xml配置" class="headerlink" title="hdfs-site.xml配置"></a>hdfs-site.xml配置</h3><pre><code>&lt;property&gt; 
    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt; 
    &lt;value&gt;master.hadoop:9001&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; 
    &lt;value&gt;/usr/local/dfs/name&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt;
    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
    &lt;value&gt;/usr/local/dfs/data&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;dfs.replication&lt;/name&gt; 
    &lt;value&gt;3&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt; 
    &lt;value&gt;true&lt;/value&gt; 
&lt;/property&gt;
</code></pre><h3 id="mapred-site-xml配置"><a href="#mapred-site-xml配置" class="headerlink" title="mapred-site.xml配置"></a>mapred-site.xml配置</h3><pre><code>&lt;property&gt; 
    &lt;name&gt;mapreduce.framework.name&lt;/name&gt; 
    &lt;value&gt;yarn&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;mapreduce.job.tracker&lt;/name&gt; 
    &lt;value&gt;hdfs://master.hadoop:9101&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt; 
    &lt;value&gt;master.hadoop:10020&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt; 
    &lt;value&gt;master.hadoop:19888&lt;/value&gt; 
&lt;/property&gt;
</code></pre><h3 id="slaves配置"><a href="#slaves配置" class="headerlink" title="slaves配置"></a>slaves配置</h3><p>添加：</p>
<pre><code>slave1.hadoop 
</code></pre><h3 id="yarn-env-sh配置"><a href="#yarn-env-sh配置" class="headerlink" title="yarn-env.sh配置"></a>yarn-env.sh配置</h3><pre><code>export JAVA_HOME=/usr/local/java/jdk1.7.0_79
</code></pre><h3 id="yarn-site-xml配置"><a href="#yarn-site-xml配置" class="headerlink" title="yarn-site.xml配置"></a>yarn-site.xml配置</h3><pre><code>&lt;property&gt; 
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; 
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt; yarn.nodemanager.aux-services.mapreduce.shuffle.class &lt;/name&gt; 
    &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; 
    &lt;value&gt;master.hadoop:8032&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt; 
    &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; 
    &lt;value&gt;master.hadoop:8030&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; 
    &lt;value&gt;master.hadoop:8031&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; 
    &lt;value&gt;master.hadoop:8033&lt;/value&gt; 
&lt;/property&gt; 

&lt;property&gt; 
    &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; 
    &lt;value&gt;master.hadoop:8088&lt;/value&gt; 
&lt;/property&gt;
</code></pre><h3 id="部署其他Slave节点"><a href="#部署其他Slave节点" class="headerlink" title="部署其他Slave节点"></a>部署其他Slave节点</h3><p>使用scp方式，例：</p>
<pre><code>scp –r /usr/local/hadoop/ root@slave1.hadoop:/usr/local/
</code></pre><p>通过scp命令将hadoop复制拷贝到slave1.hadoop上</p>
<h2 id="启动关闭Hadoop"><a href="#启动关闭Hadoop" class="headerlink" title="启动关闭Hadoop"></a>启动关闭Hadoop</h2><h3 id="关闭防火墙"><a href="#关闭防火墙" class="headerlink" title="关闭防火墙"></a>关闭防火墙</h3><p>centOS7原有防火墙：</p>
<pre><code>systemctl start firewalld.service#启动firewall
systemctl stop firewalld.service#停止firewall
systemctl disable firewalld.service#禁止firewall开机启动
</code></pre><p>centOS7自定义防火墙：</p>
<pre><code>service iptables stop 
</code></pre><h3 id="格式化HDFS文件"><a href="#格式化HDFS文件" class="headerlink" title="格式化HDFS文件"></a>格式化HDFS文件</h3><p>只需要格式化一次即可，之后重启不必再进行格式化</p>
<pre><code>cd /usr/local/hadoop/bin
hadoop namenode –format
</code></pre><h3 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h3><p>正在在这里一并验证下 ssh 无密码登陆服务，如下图所示：</p>
<p><img src="http://i.imgur.com/zOdoJzz.png" alt=""></p>
<p>启动 master.hadoop 上的 hadoop</p>
<pre><code>cd /usr/local/hadoop/sbin
start-all.sh
</code></pre><p><img src="http://i.imgur.com/8RS4eZ8.png" alt=""></p>
<p>在这里我们可以看到 slave1 上的 datanode和nodemanager也启动了，让我们在终端看看：</p>
<p>master：</p>
<p><img src="http://i.imgur.com/0DzxQ3d.png" alt=""></p>
<p>slave1：</p>
<p><img src="http://i.imgur.com/PGXDywo.png" alt=""></p>
<p>ok，到这里没有问题。我们在终端发现所有的需要的节点都已经启动了，接下来在浏览器中验证一下：</p>
<p>输入： <a href="http://master.hadoop:8088/cluster" target="_blank" rel="external">http://master.hadoop:8088/cluster</a></p>
<p><img src="http://i.imgur.com/QciKqE2.png" alt=""></p>
<p>这里可以看到节点已经启动成功。</p>
<p>输入： <a href="http://master.hadoop:50070" target="_blank" rel="external">http://master.hadoop:50070</a></p>
<p><img src="http://i.imgur.com/9LqtL6j.png" alt=""></p>
<p>在这里可以得到更多的监控信息。</p>
<p>到这里为止，Hadoop集群搭建就告一段落了，赶快动手行动起来吧！</p>
<p>预告：后续会写一些集群上服务的搭建，像hbase,hive等等······</p>
<p>一直学习，一直进步······</p>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/04/18/CentOS7安装Eclipse/" itemprop="url">
                  CentOS7安装Eclipse（该文章还未写）
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-04-18T19:24:07+08:00" content="2016-04-18">
              2016-04-18
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
                  ， 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/Eclipse/" itemprop="url" rel="index">
                    <span itemprop="name">Eclipse</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/04/18/CentOS7安装Eclipse/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/04/18/CentOS7安装Eclipse/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
		  
		  

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="下载Eclipse"><a href="#下载Eclipse" class="headerlink" title="下载Eclipse"></a>下载Eclipse</h1><p><a href="http://mirrors.noc.im/apache/hbase/hbase-1.0.3/" target="_blank" rel="external">http://mirrors.noc.im/apache/hbase/hbase-1.0.3/</a></p>
<h1 id="解压安装Eclipse"><a href="#解压安装Eclipse" class="headerlink" title="解压安装Eclipse"></a>解压安装Eclipse</h1>
          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/04/18/Hadoop-WordCount-运行实例/" itemprop="url">
                  Hadoop WordCount 运行实例
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-04-18T14:38:34+08:00" content="2016-04-18">
              2016-04-18
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
                  ， 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/04/18/Hadoop-WordCount-运行实例/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/04/18/Hadoop-WordCount-运行实例/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
		  
		  

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Hadoop中的WordCount就像是其他编程语言的HelloWorld一样，引导我们学习的开始</p>
<hr>
<p>进入终端：</p>
<pre><code>首先进入hadoop目录： [root@localhost ~]# cd /home/hadoop/hadoop-2.7.1

启动Hadoop: [root@localhost hadoop-2.7.1]# ./sbin/start-all.sh

在HDFS中创建input文件目录： hadoop fs -mkdir /input2
</code></pre><p>新建一个文件：</p>
<pre><code>[root@localhost hadoop-2.7.1]# vi /home/hadoop/hadoop-2.7.1/dy02.txt 
</code></pre><p>输入： Hello Hadoop,I am Dayong ! I love China ! I love learning Hadoop !</p>
<pre><code>放到hdfs的input目录下面： hadoop fs -put /home/hadoop/hadoop-2.7.1/dy02.txt  /input2

查看文件是否正确传入到/input目录下： localhost hadoop-2.7.1]# hadoop fs -ls /input2

查看文件内容： hadoop fs -cat /input2/dy02.txt
</code></pre><p>准备好这些，就可以执行wordcount实例了：</p>
<pre><code>hadoop jar /home/hadoop/hadoop-2.7.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.1.jar wordcount /input2 /output2
</code></pre><p>查看输出结果的目录：</p>
<pre><code>hadoop fs -ls /output2
</code></pre><p>查看输出结果：</p>
<pre><code>hadoop fs -cat /output2/part-r-00000
</code></pre><p><img src="http://i.imgur.com/QrZ1aPY.png" alt=""></p>
<p>这样我们就算真正的开始了Hadoop之旅，下面就进入更加深奥的探索吧！</p>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
      

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                
                <a class="post-title-link" href="/2016/04/15/VMware下CentOS7配置hadoop/" itemprop="url">
                  VMware下CentOS7配置hadoop(单机版)
                </a>
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-04-15T11:45:14+08:00" content="2016-04-15">
              2016-04-15
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
                  ， 
                

              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/Linux/Hadoop/" itemprop="url" rel="index">
                    <span itemprop="name">Hadoop</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/04/15/VMware下CentOS7配置hadoop/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/04/15/VMware下CentOS7配置hadoop/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          
		  
		  

          
          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="JDK的安装请见上一篇《CentOS7-JDK-环境搭建》"><a href="#JDK的安装请见上一篇《CentOS7-JDK-环境搭建》" class="headerlink" title="JDK的安装请见上一篇《CentOS7 JDK 环境搭建》"></a>JDK的安装请见上一篇《CentOS7 JDK 环境搭建》</h1><h1 id="SSH服务安装与无密码登陆设置"><a href="#SSH服务安装与无密码登陆设置" class="headerlink" title="SSH服务安装与无密码登陆设置"></a>SSH服务安装与无密码登陆设置</h1><h2 id="安装SSH服务"><a href="#安装SSH服务" class="headerlink" title="安装SSH服务"></a>安装SSH服务</h2><h3 id="SSH简介："><a href="#SSH简介：" class="headerlink" title="SSH简介："></a>SSH简介：</h3><ul>
<li>SSH 为 Secure Shell 的缩写，由 IETF 的网络工作小组（Network Working Group）所制定；</li>
<li>SSH 为建立在应用层和传输层基础上的安全协议。SSH 是目前较可靠，专为远程登录会话和其他网络服务提供安全性的协议。</li>
<li>利用 SSH 协议可以有效防止远程管理过程中的信息泄露问题。</li>
<li>透过 SSH 可以对所有传输的数据进行加密，也能够防止 DNS 欺骗和 IP 欺骗。</li>
</ul>
<h3 id="SSH安装"><a href="#SSH安装" class="headerlink" title="SSH安装"></a>SSH安装</h3><ul>
<li>这里我用的是CentOS7,OpenSSH是默认安装的。</li>
</ul>
<hr>
<ul>
<li>检测SSH是否安装？ 打开终端，输入ssh，如下所示则表明已经安装了SSH</li>
</ul>
<hr>
<pre><code>[root@localhost ~]# ssh
</code></pre><hr>
<ul>
<li>usage: ssh [-1246AaCfgKkMNnqsTtVvXxYy] [-b bind_address] [-c cipher_spec]</li>
<li>[-D [bind_address:]port] [-E log_file] [-e escape_char]</li>
<li>[-F configfile] [-I pkcs11] [-i identity_file]</li>
<li>[-L [bind_address:]port:host:hostport] [-l login_name] [-m mac_spec]</li>
<li>[-O ctl_cmd] [-o option] [-p port]</li>
<li>[-Q cipher | cipher-auth | mac | kex | key]</li>
<li>[-R [bind_address:]port:host:hostport] [-S ctl_path] [-W host:port]</li>
<li>[-w local_tun[:remote_tun]] [user@]hostname [command]</li>
</ul>
<hr>
<p>若没有安装，则在终端执行下面的命令进行安装</p>
<hr>
<pre><code>yum install ssh
</code></pre><hr>
<h3 id="SSH启动"><a href="#SSH启动" class="headerlink" title="SSH启动"></a>SSH启动</h3><pre><code>[root@localhost ~]# service sshd start
</code></pre><hr>
<h3 id="SSH开机运行"><a href="#SSH开机运行" class="headerlink" title="SSH开机运行"></a>SSH开机运行</h3><hr>
<pre><code>[root@localhost ~]# chkconfig sshd on
</code></pre><hr>
<h2 id="配置ssh免密码登录"><a href="#配置ssh免密码登录" class="headerlink" title="配置ssh免密码登录"></a>配置ssh免密码登录</h2><hr>
<h3 id="检查配置"><a href="#检查配置" class="headerlink" title="检查配置"></a>检查配置</h3><hr>
<p>Hadoop需要通过SSH来启动Slave节点的守护进程，即使安装伪分布式也需要SSH。<br>除了ssh外还需要rsync服务，rsync是一个远程数据同步工具，可通过LAN/WAN快速同步多台主机间的文件。<br>判断ssh和rsync有没有安装</p>
<p>rpm –qa | grep openssh</p>
<p>rpm –qa | grep rsync</p>
<p>如果没有安装使用以下命令安装</p>
<p>yum install ssh 安装SSH协议</p>
<p>yum install rsync </p>
<hr>
<h3 id="配置免密码登录"><a href="#配置免密码登录" class="headerlink" title="配置免密码登录"></a>配置免密码登录</h3><hr>
<h4 id="免密码登录的原理"><a href="#免密码登录的原理" class="headerlink" title="免密码登录的原理"></a>免密码登录的原理</h4><ul>
<li><p>Master（NameNode | JobTracker）作为客户端，要实现无密码公钥认证，连接到服务器Salve（DataNode | Tasktracker）上时，<br>需要在Master上生成一个密钥对，包括一个公钥和一个私钥，而后将公钥复制到所有的Slave上。</p>
</li>
<li><p>当Master通过SSH连接Salve时，Salve就会生成一个随机数并用Master的公钥对随机数进行加密，并发送给Master。</p>
</li>
<li><p>Master收到加密数之后再用私钥解密，并将解密数回传给Slave，Slave确认解密数无误之后就允许Master进行连接了。</p>
</li>
</ul>
<p>这就是一个公钥认证过程，其间不需要用户手工输入密码。<br>重要过程是将客户端Master复制到Slave上。</p>
<hr>
<h4 id="免密码登录实现"><a href="#免密码登录实现" class="headerlink" title="免密码登录实现"></a>免密码登录实现</h4><hr>
<p><strong>1，使用普通用户登录CentOS。进入用户的home目录，执行如下命令</strong></p>
<pre><code>$ ssh-keygen -t rsa -P &apos;&apos; -f ~/.ssh/id_rsa
</code></pre><p><strong>注解：</strong></p>
<ol>
<li>ssh-keygen表示生成密钥；</li>
<li>-t指定密钥类型；</li>
<li>-P 提供密语；</li>
<li>-f生成的密钥文件</li>
</ol>
<p>这条语句表示生成了一个无密码密钥对，此时目录下会生成id_rsa和id_rsa.pub两个文件，前者是私钥，后者是公钥</p>
<hr>
<p><strong>2，将公钥追加到授权key中</strong></p>
<hr>
<pre><code>$ cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre><hr>
<p><strong>3，将授权key文件权限改为600（rr——-）</strong></p>
<hr>
<pre><code>$ chmod 600 ~/.ssh/authorized_keys
</code></pre><hr>
<p><strong>4,切换到root用户，修改ssh配置文件</strong></p>
<hr>
<pre><code>vim /etc/ssh/sshd_config
</code></pre><hr>
<p>修改其中部分内容（去掉原来的注释符号）</p>
<ol>
<li>RSAAuthentication yes # 启用 RSA 认证</li>
<li>PubkeyAuthentication yes # 启用公钥私钥配对认证方式</li>
<li>AuthorizedKeysFile .ssh/authorized_keys # 公钥文件路径（和上面生成的文件同）</li>
</ol>
<p>退出root用户，验证是否可以免密码登陆</p>
<hr>
<pre><code>[root@localhost ~]# ssh localhost
</code></pre><hr>
<p>Last login: Fri Apr 15 12:04:33 2016 from localhost</p>
<p>这样就成功的登陆SSH了</p>
<h2 id="这篇文章介绍的很详细：http-www-ithao123-cn-content-8728381-html"><a href="#这篇文章介绍的很详细：http-www-ithao123-cn-content-8728381-html" class="headerlink" title="这篇文章介绍的很详细：http://www.ithao123.cn/content-8728381.html"></a>这篇文章介绍的很详细：<a href="http://www.ithao123.cn/content-8728381.html" target="_blank" rel="external">http://www.ithao123.cn/content-8728381.html</a></h2><h1 id="创建hadoop用户"><a href="#创建hadoop用户" class="headerlink" title="创建hadoop用户"></a>创建hadoop用户</h1><hr>
<pre><code>[root@localhost ~]# useradd -d /home/hadoop -s /bin/bash hadoop

[root@localhost ~]# passwd hadoop
</code></pre><hr>
<p>设置好密码后，可以将hadoop用户添加到sudoer列表，在终端键入：</p>
<hr>
<pre><code>[root@localhost ~]# visudo
</code></pre><hr>
<p>然后在 <strong>root    ALL=(ALL)       ALL</strong> 下面添加hadoop用户配置，如下：</p>
<hr>
<pre><code>root    ALL=(ALL)       ALL
hadoop  ALL=(ALL)       ALL 
</code></pre><hr>
<p>接下来就是重头戏了，安装hadoop正式开始</p>
<hr>
<h1 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h1><hr>
<p><strong>说明：我这里使用的是root账号，接下来也是单机版hadoop安装，伪分布式和分布式安装待以后有时间写，想了解的也可以给我留言。</strong></p>
<hr>
<h2 id="准备工作："><a href="#准备工作：" class="headerlink" title="准备工作："></a><strong>准备工作：</strong></h2><ol>
<li><p>下载Hadoop,这里我下载的是 hadoop-2.7.1</p>
<ul>
<li>链接：<a href="http://pan.baidu.com/s/1c27EnPu" target="_blank" rel="external">http://pan.baidu.com/s/1c27EnPu</a> 密码：h5rg</li>
</ul>
</li>
</ol>
<hr>
<h2 id="操作步骤"><a href="#操作步骤" class="headerlink" title="操作步骤:"></a><strong>操作步骤:</strong></h2><h3 id="将下载好的hadoop压缩文件解压在home目录下的hadoop文件夹下"><a href="#将下载好的hadoop压缩文件解压在home目录下的hadoop文件夹下" class="headerlink" title="将下载好的hadoop压缩文件解压在home目录下的hadoop文件夹下"></a>将下载好的hadoop压缩文件解压在home目录下的hadoop文件夹下</h3><hr>
<pre><code>创建home/hadoop目录: mkdir /home/hadoop

将hadoop压缩文件移动到hadoop文件夹下面： mv /usr/hadoop-2.7.1.tar.gz /home/hadoop

解压压缩文件到该目录： tar xvf hadoop-2.7.1.tar.gz

这样解压完后可以删除压缩文件了： rm hadoop-2.7.1.tar.gz
</code></pre><h3 id="到-home-hadoop-目录下新建几个文件夹"><a href="#到-home-hadoop-目录下新建几个文件夹" class="headerlink" title="到 /home/hadoop 目录下新建几个文件夹"></a>到 /home/hadoop 目录下新建几个文件夹</h3><hr>
<pre><code>mkdir tmp

mkdir hdfs

mkdir hdfs/name

mkdir hdfs/data
</code></pre><h3 id="Hadoop-核心文件配置"><a href="#Hadoop-核心文件配置" class="headerlink" title="Hadoop 核心文件配置"></a>Hadoop 核心文件配置</h3><hr>
<pre><code>在终端输入： gedit /home/hadoop/hadoop-2.7.1/etc/hadoop/core-site.xml
</code></pre><p>添加：</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
        &lt;value&gt;file:/home/hadoop/tmp&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;io.file.buffer.size&lt;/name&gt;
        &lt;value&gt;131702&lt;/value&gt;
    &lt;/property&gt;
 &lt;/configuration&gt;
</code></pre><hr>
<pre><code>在终端输入： gedit /home/hadoop/hadoop-2.7.1/etc/hadoop/hdfs-site.xml
</code></pre><p>添加：</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
        &lt;value&gt;file:/home/hadoop/hdfs/name&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
        &lt;value&gt;file:/home/hadoop/hdfs/data&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.replication&lt;/name&gt;
        &lt;value&gt;2&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        &lt;value&gt;localhost:9001&lt;/value&gt;
    &lt;/property&gt;
    &lt;property&gt;
        &lt;name&gt;dfs.webhdfs.enabled&lt;/name&gt;
        &lt;value&gt;true&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><hr>
<ul>
<li>mapred-site.xml 这个文件不存在，存有的是 mapred-queues.xml.template 这个文件，</li>
<li>复制mapred-site.xml.template一份，并把名字改为mapred-site.xml</li>
</ul>
<hr>
<pre><code>在终端输入： gedit /home/hadoop/hadoop-2.7.1/etc/hadoop/mapred-site.xml
</code></pre><p>添加：</p>
<pre><code>&lt;configuration&gt;
    &lt;property&gt;
        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
        &lt;value&gt;yarn&lt;/value&gt;
    &lt;/property&gt;
&lt;/configuration&gt;
</code></pre><hr>
<p>是不是很简单，这样子你的单机版的hadoop到此为止就已经配置完成了，下面我们一一验证是否成功吧</p>
<h1 id="验证Hadoop是否可以成功启动"><a href="#验证Hadoop是否可以成功启动" class="headerlink" title="验证Hadoop是否可以成功启动"></a>验证Hadoop是否可以成功启动</h1><h3 id="格式化hdfs"><a href="#格式化hdfs" class="headerlink" title="格式化hdfs"></a>格式化hdfs</h3><pre><code>执行： cd home/hadoop/hadoop-2.7.1 进入hadoop目录

格式化hdfs: bin/hadoop namenode -format
</code></pre><p><img src="http://i.imgur.com/UAD4NVG.png" alt=""></p>
<p>出现如上图所示的那句话，就是格式化成功啦！！！接下来我们启动所有服务，拭目以待。</p>
<hr>
<h3 id="启动服务"><a href="#启动服务" class="headerlink" title="启动服务"></a>启动服务</h3><pre><code>执行： ./sbin/start-all.sh 启动所有服务
</code></pre><p>也可以分开执行：</p>
<pre><code>./sbin/start-dfs.sh
./sbin/start-yarn.sh
</code></pre><hr>
<h3 id="浏览器查看监控信息"><a href="#浏览器查看监控信息" class="headerlink" title="浏览器查看监控信息"></a>浏览器查看监控信息</h3><h4 id="HDFS监控"><a href="#HDFS监控" class="headerlink" title="HDFS监控"></a>HDFS监控</h4><p>在浏览器输入： <a href="http://localhost:50070" target="_blank" rel="external">http://localhost:50070</a></p>
<p>效果如下：</p>
<p><img src="http://i.imgur.com/fLLNgKI.png" alt=""></p>
<h4 id="Map-Reduce监控"><a href="#Map-Reduce监控" class="headerlink" title="Map-Reduce监控"></a>Map-Reduce监控</h4><p>在浏览器输入： <a href="http://localhost:8088" target="_blank" rel="external">http://localhost:8088</a></p>
<p><img src="http://i.imgur.com/CsZbAMK.png" alt=""></p>
<hr>
<h1 id="后续"><a href="#后续" class="headerlink" title="后续"></a>后续</h1><hr>
<ul>
<li><p>写到这里，Hadoop单机版已经弄好，伪分布式就是多了几个节点，可以并行处理，之后有需求的话我会写一下，主要将hadoop的那几个核心文件和hosts文件重新配置一下；</p>
</li>
<li><p>这篇文章主要是为初学者提供一些信息，避免走很多弯路，如有问题的话随时欢迎给我留言，或者将问题发到我邮箱里面。</p>
</li>
</ul>

          
        
      
    </div>
    
    <div>
      
    </div>

    <div>
      
    </div>

    <footer class="post-footer">
      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      

      <section class="site-overview sidebar-panel  sidebar-panel-active ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/uploads/touxiang.png"
               alt="霸王条" />
          <p class="site-author-name" itemprop="name">霸王条</p>
          <p class="site-description motion-element" itemprop="description">这是一个数据疯子的空间</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">7</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">15</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        <div class="links-of-blogroll motion-element">
          
        </div>

      </section>

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2016</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">霸王条</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="http://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>



      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.1"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.1"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"superdayong"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
  





  
  
  

  

  
  
  

</body>
</html>
